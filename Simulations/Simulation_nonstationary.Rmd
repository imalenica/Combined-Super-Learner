---
title: "Test Nonstationary Time Series Prediction"
author: "Ivana Malenica"
date: "August 2019"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{graphicx}
- \usepackage{lscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{float}
---

```{r setup, echo = FALSE}
options(warn=-1)
suppressMessages(library(xtable))
suppressMessages(library(here))
suppressMessages(library(pROC))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(reshape2))
suppressMessages(library(forecast))
suppressMessages(library(kableExtra))
suppressMessages(library(sl3))
suppressMessages(library(origami))
suppressMessages(library(SuperLearner))
suppressMessages(library(data.table))
suppressMessages(library(ck37r))
options(xtable.comment = FALSE)
source(here::here("R", "utils_mimic.R"))
source(here::here("R", "CombinedOnlineSL.R"))
```

# Overview {-}

We may be interested in the performance of the Combined Super Learner in case 
of a nonstationary time-series. In particular, we estimate models for each 
patient, as well as a "pooled" Arima model for the combination of few individual
time-series. The idea is that the Combined Super Learner should adjust depending on 
which part of the time-series we are looking at (stationary or nonstationary parts).

# Prepare the data

We only considered patients that had:

* at least 8 hours of data.

\vspace{.2in}

336 of the 582 subjects experienced at least one hypotensive event, and the 
outcome `Y1` was used to specify hypotensive events. The hypotensive patients 
were classified as any patient that exhibited a hypotensive event. The 
non-hypotensive never experienced a hypotensive event.

\vspace{.2in}
```{r editdata, echo = FALSE, message = FALSE, warning = FALSE}
load(here::here("Data", "mimic_im.Rdata"))

#Limit data to the first 8 hours
dat <- mimic %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(time=1:n()) %>%
  dplyr::mutate(init_time_and_date = min(time_and_date)) %>%
  dplyr::mutate(min_elapsed = as.integer((time_and_date -
                                            init_time_and_date) / 60) + 1) %>%
  dplyr::filter(min_elapsed <= 480)

#PROBLEM: it seems that some samples have even longer breaks, 
#resulting in shorter amount of data (but the same elapsed time)
#Samples with 8 hours of data (note, this includes the missing data)
df_full <- dat %>%
  dplyr::group_by(subject_id) %>%
  dplyr::filter(time == 330)

dat <- dat[(dat$subject_id %in% df_full$subject_id),]
df <- dat[order(dat$subject_id, dat$time_and_date),]
rm(dat, df_full, mimic)

df <- df %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(hypo_event = sum(Y1)) %>%
  dplyr::mutate(event=ifelse(hypo_event > 1,1,0))

#How many samples had an episode?
#336 with at least one episode, 246 with no episodes.
events <- df %>% 
  dplyr::select(c("subject_id", "hypo_event")) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::summarize_all(unique)
  
#Samples with events:
sample_y1<-events[events$hypo_event>0,1]
#Samples with no events:
sample_y0<-events[events$hypo_event==0,1]
```

# Create ARIMA models for each patient

Selects the optimal autoregressive and moving average orders $p$ 
and $q$ based on a chosen information criterion (AICc by default) from a local 
search over a few regions of values. In parricular, we fit individual ARIMA models
as well as a pooled ARIMA model estimated from multiple time-series.

```{r model, echo = FALSE, eval = FALSE, message = FALSE, warning = FALSE}
run_auto_arima <- function(df, outcome = "abpmean", id=NULL, pool=TRUE) {
  
  auto_arima<- function(x){
      
      # 1. subset data to only contain that sample and make sure it's in order
      sub <- df[df$subject_id == x, ]
      sub_ord <- sub[order(sub$time_and_date), ]

      # 2. split first 80% of data into training set, and last 20% into test set
      split <- round(nrow(sub_ord) * .8)
      train <- sub_ord[1:split, ]
      train_outcome <- as.numeric(unlist(train[,which(colnames(train)==outcome)]))
      test <- sub_ord[(split + 1):nrow(sub_ord), ]
      test_outcome <- as.numeric(unlist(test[,which(colnames(test) == outcome)]))

      # 3. fit auto ARIMA
      fit <- auto.arima(y = train_outcome, stepwise = FALSE,
                                approximation = FALSE)

      # 4. obtain model coefficients                                          
      fit_coef <- fit$coef

      # 5. calculate residuals for subseuqent ACF and PACF plotting
      fit_resid <- residuals(fit)

      # 6. measure accuracy
      # one-step forecast
      model_test <- Arima(test_outcome, model = fit)
      onestep_forecast <- fitted(model_test)
      # accuracy of the one-step ahead out of sample forecasts
      onestep_accuracy <- round(accuracy(model_test), 4)

      plot_info <- list(onestep_forecast = onestep_forecast,
                        test = test_outcome)

      # 7. make relevant results pretty and return them
      accuracy_onestep <- onestep_accuracy["Training set",]

      return(list(fit = fit,
                coefficients = fit_coef,
                accuracy = accuracy_onestep,
                plot_info = plot_info,
                residuals = fit_resid))
  }
  
  if(pool){
    
    #######################################
    ### Pooled ARIMA, across all samples
    #######################################
   
    samples <- unique(df$subject_id)
    
    train_test_samples <- lapply(samples, function(x){
      # 1. subset data to only contain that sample and make sure it's in order
      sub <- df[df$subject_id == x, ]
      sub_ord <- sub[order(sub$time_and_date), ]
      
      # 2. split first 80% of data into training set, and last 20% into test set
      split <- round(nrow(sub_ord) * .8)
      train <- sub_ord[1:split, ]
      train_outcome <- as.numeric(unlist(train[,which(colnames(train)==outcome)]))
      test <- sub_ord[(split + 1):nrow(sub_ord), ]
      test_outcome <- as.numeric(unlist(test[,which(colnames(test) == outcome)]))
      
      return(list(train_outcome= train_outcome,
                  test_outcome=test_outcome))
    })
    
    #Pad individual time-series with a 30 min period.
    train_test_samples<-lapply(train_test_samples, function(x){
      x$train_outcome <- c(rep(NA, 60), x$train_outcome)
      return(list(train_outcome=x$train_outcome,
                  test_outcome=x$test_outcome))
    })
    
    #Combined all the train time-series into one:
    train_pooled <- ts(unlist(lapply(train_test_samples, function(x){x$train_outcome})))
    test_pooled <- ts(unlist(lapply(train_test_samples, function(x){x$test_outcome})))

    # 3. fit auto ARIMA
    fit <- auto.arima(y = train_pooled, stepwise = FALSE,
                                approximation = FALSE)

    # 4. obtain model coefficients                                          
    fit_coef <- fit$coef

    # 5. calculate residuals for subseuqent ACF and PACF plotting
    fit_resid <- residuals(fit)

    # 6. measure pooled accuracy
    model_test <- Arima(test_pooled, model = fit)
    onestep_forecast <- fitted(model_test)
    onestep_accuracy <- round(accuracy(model_test), 4)
    plot_info_pooled <- list(onestep_forecast = onestep_forecast,
                                  test = test_pooled)
    accuracy_onestep_pooled <- onestep_accuracy["Training set",]
    
    # 7. measure individual accuracy
    indiv_stats<-lapply(train_test_samples, function(x){
      model_test <- Arima(x$test_outcome, model = fit)
      onestep_forecast <- fitted(model_test)
      onestep_accuracy <- round(accuracy(model_test), 4)
      plot_info <- list(onestep_forecast = onestep_forecast,
                                  test = x$test_outcome)
      accuracy_onestep <- onestep_accuracy["Training set",]
      return(list(accuracy_onestep=accuracy_onestep,
                  plot_info=plot_info))
    })
    list_acc <- lapply(indiv_stats, function(x) data.frame(as.list(x$accuracy_onestep)))
    list_acc <- list_acc[lapply(list_acc, length) > 0]
    accuracy <- rbindlist(list_acc, fill = TRUE)
    accuracy <- data.frame(subject_id = samples, accuracy)
    plot_info <- lapply(indiv_stats, function(x) x$plot_info)
    names(plot_info) <- samples
    
    return(list(fit = fit,
                coefficients = fit_coef,
                accuracy_pooled = accuracy_onestep_pooled,
                accuracy = accuracy,
                plot_data_pooled = plot_info_pooled,
                plot_data = plot_info,
                residuals = fit_resid
                ))
  }else if(!pool){
    
    #######################################
    ### Separate ARIMA for each time-series
    #######################################
    
    if(is.null(id)){
      
      #Fit on all samples in df
      samples <- unique(df$subject_id)
      
      # for each sample:
      fit_list <- lapply(samples, auto_arima)
      
      # make results pretty
      names(fit_list) <- samples
      
      list_coef <- lapply(fit_list, function(x) data.frame(as.list(x$coefficients)))
      list_coef <- list_coef[lapply(list_coef, length) > 0]
      coefficients <- rbindlist(list_coef, fill = TRUE)
      coefficients <- data.frame(subject_id = names(list_coef), coefficients)
      list_acc <- lapply(fit_list, function(x) data.frame(as.list(x$accuracy)))
      list_acc <- list_acc[lapply(list_acc, length) > 0]
      accuracy <- rbindlist(list_acc, fill = TRUE)
      accuracy <- data.frame(subject_id = names(list_acc), accuracy)
      plot_data <- lapply(fit_list, function(x) x$plot_info)
      names(plot_data) <- samples
      residuals <- lapply(fit_list, function(x) x$residuals)
      names(residuals) <- samples

      fit <- lapply(fit_list, function(x) x$fit)
      names(fit) <- samples

      return(list(fit = fit,
                  coefficients = coefficients,
                  accuracy = accuracy,
                  plot_data = plot_data,
                  residuals = residuals))
      
    }else if(!is.null(id)){
     
      # Fit only on the single specified sample
      
      fit_list <- auto_arima(x=id)

      return(list(fit = fit_list$fit,
                  coefficients = fit_list$coefficients,
                  accuracy = fit_list$accuracy,
                  plot_data = fit_list$plot_info,
                  residuals = fit_list$residuals))
    }
  }
}
```

```{r fit, echo = FALSE, eval = FALSE, message = FALSE, warning = FALSE}
set.seed(4197)

#Get a pooled model over a subsample:
#(on purpose, do not create too-good-models)
sub_sample_y1 <- base::sample(sample_y1$subject_id, size=100)
sub_sample_y0 <- base::sample(sample_y0$subject_id, size=100)
#sub_sample_y1<-sample_y1$subject_id
#sub_sample_y0<-sample_y0$subject_id
sub_samples<-c(sub_sample_y1,sub_sample_y0)
sub_df<-df[df$subject_id %in% sub_samples,]

fit_pooled <- run_auto_arima(df=sub_df, outcome = "abpmean", pool=TRUE)
fit_individuals<-lapply(as.list(sub_sample_y1), function(id){
  run_auto_arima(df=sub_df,outcome = "abpmean",id=id,pool=FALSE)
})
names(fit_individuals) <- sub_sample_y1
save(fit_pooled, file = here::here("Results/Nonstationary_ts", "fit_pooled.Rdata"),
     compress = TRUE)
save(fit_individuals, file = here::here("Results/Nonstationary_ts", "fit_individuals.Rdata"),
     compress = TRUE)
save(sub_samples, file = here::here("Results/Nonstationary_ts", "sub_samples.Rdata"),
     compress = TRUE)
```

\newpage

## Examine accuracy of one-step ahead forecasts

We examined the accuracy of one-step ahead forecasts with the mean absolute error 
(MAE)  = $\text{mean}(|e_t|)$. Below we give an example where the indvidual fit 
(first two graphs) and pooled fit (last two graphs) gives a better result in terms 
of MAE for different random samples. 

```{r, echo = FALSE, message = FALSE, warning = FALSE}
load(here::here("Results/Nonstationary_ts","fit_pooled.Rdata"))
load(here::here("Results/Nonstationary_ts","fit_individuals.Rdata"))
load(here::here("Results/Nonstationary_ts","sub_samples.Rdata"))

##Pooled stats
#Pooled vs. assessed on separate models accuracy
acc_all <- rbind.data.frame(fit_pooled$accuracy_pooled, fit_pooled$accuracy)
acc_all[1,1]<-"pooled"
#acc_all %>%
#  kable(format = "latex", booktabs = T, digits = 4, longtable = T,
#        caption = "Accuracy of pooled ARIMA one-step forecasts used for simulation") %>%
#  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 7,
#                position = "center")

##Individual stats
acc_ind <- t(rbind_list(lapply(fit_individuals, function(x){x$accuracy})))
acc_ind <- cbind.data.frame(row.names(acc_ind), acc_ind)
colnames(acc_ind) <- names(acc_all)
row.names(acc_ind) <- NULL
#acc_ind %>%
#  kable(format = "latex", booktabs = T, digits = 4, longtable = T,
#        caption = "Accuracy of ARIMA one-step forecasts used for simulation") %>%
#  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 7,
#                position = "center")

#Combine results to compare:
acc_comb <- merge(x=acc_all[,c("subject_id", "MAE")], 
                  acc_ind[,c("subject_id", "MAE")],  by="subject_id")
names(acc_comb)[2:3] <- c("MAE pooled", "MAE individual")
acc_comb %>%
  kable(format = "latex", booktabs = T, digits = 4, longtable = T,
        caption = "Compare MAE for pooled and individual forecasts") %>%
  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 7,
                position = "center")
#test<-acc_comb[acc_comb$`MAE individual`>acc_comb$`MAE pooled`,]
```

```{r, echo = FALSE, fig.align = "center", fig.width = 4, fig.height = 4, message = FALSE, warning = FALSE}
##Example: check how well the prediction of the pooled ARIMA looks on a sample
plot_forecast <- function(type=c("pooled", "individual", "time-series"), ts=NULL, id) {
  
  if(type=="pooled"){
     
    #Take the pooled prediction for sample id:
    onestep_forecast <- fit_pooled$plot_data[[as.character(id)]]$onestep_forecast
    test_outcome <- fit_pooled$plot_data[[as.character(id)]]$test
    
    return(ggplot() +
           geom_line(aes(x = as.numeric(time(test_outcome)),
                         y = as.numeric(test_outcome),
                         col = "blue")) +
           geom_line(aes(x = as.numeric(time(onestep_forecast)),
                         y = as.numeric(onestep_forecast),
                         col = "red")) +
           scale_color_discrete(name = "",
                                labels = c("truth", "pooled forecast")) +
           labs(title = paste0(type, " fit for subject ", id),
                x = "Time in test set (minutes)",
                y = "Mean blood pressure") +
           theme(legend.position="top"))
    }else if(type=="individual"){
      
    #Take the individual prediction for sample id:
    onestep_forecast <- fit_individuals[[as.character(id)]]$plot_data$onestep_forecast
    test_outcome <- fit_individuals[[as.character(id)]]$plot_data$test
    
    return(ggplot() +
           geom_line(aes(x = as.numeric(time(test_outcome)),
                         y = as.numeric(test_outcome),
                         col = "blue")) +
           geom_line(aes(x = as.numeric(time(onestep_forecast)),
                         y = as.numeric(onestep_forecast),
                         col = "red")) +
           scale_color_discrete(name = "",
                                labels = c("truth", "individual forecast")) +
           labs(title = paste0(type, " fit for subject ", id),
                x = "Time in test set (minutes)",
                y = "Mean blood pressure") +
           theme(legend.position="top"))
    
  }else if("time-series"){
    return(ggplot() +
           geom_line(aes(x = as.numeric(time(ts)),
                         y = as.numeric(ts),
                         col = "blue")) +
           scale_color_discrete(name = "",
                                labels = c("time-series")) +
           labs(title = paste0("Time-Series for subject ", id),
                x = "Time in test set (minutes)",
                y = "Mean blood pressure") +
           theme(legend.position="top"))
  }
}

#Example of individual forecast doing better
plot_forecast(type = "individual", id = 20403)
plot_forecast(type = "pooled", id = 20403)

#Example of pooled forecast doing better
plot_forecast(type = "individual", id = 11380)
plot_forecast(type = "pooled", id = 11380)

```

\normalsize
\newpage

# Simulate from ARIMA models

We use the ARIMA fitted models to simulate 
time series. We simulate from both individual 
trajectories and pooled trajectories, while adding extra noise. 
In particular, we combine the two time-series generated at random times
through-out the time-series, creating an interrupted time-series at 
`t=2` times.  

* By default, the error series is assumed normally distributed and generated 
  using `rnorm`. However, we set `bootstrap=TRUE`, so the residuals are 
  resampled instead. Also, we set `future=TRUE`, so the sample paths are 
  conditional on the data that was used to fit the model. 

* When `future=FALSE` and the model is stationary, the sample paths do not 
  depend on the data at all. When `future=FALSE` and the model is 
  non-stationary, the location of the sample paths is arbitrary, so they all 
  start at the value of the first observation.
  
```{r, eval = FALSE, echo = FALSE, warning = FALSE}

# id = Subject id to simulate from
# t = Number of times we want to interrupt the individual-based-model time-series.
# niter = Number of time series simulations for specified model.
# nsim	= Number of periods for the simulated series.
# bootstrap = Do simulation using resampled errors rather than normally 
#             distributed errors or errors provided as innov.
# future = Produce sample paths that are future to and conditional on the data 
#          in object. Otherwise simulate unconditionally.
# seed = Either NULL or an integer that will be used in a call to set.seed 
#        before simulating the time series.
# noise = If true, we add extra white noise to the model.

#Note: 330 will correspond to total of 8 hours of data
run_simulation <- function(id=20403, t=2, niter = 1, 
                           nsim = 330, seed = 4197, future = TRUE, 
                           bootstrap = TRUE, noise=TRUE) {
  
  ####TO DO: add the niter option; for now simulate just once

  #Get the pooled model
  model_pool <- fit_pooled$fit
  #Get the individual model
  model_individual <- fit_individuals[[as.character(id)]]$fit
  
  #Get the individual (baseline) covariates:
  W <- df[df$subject_id==id, c("gender",  "age","care_unit", "admission_type_descr", 
                      "sapsi_first", "sofa_first",
                      "amine","sedation","ventilation")]
  
  #Simulate individual and pooled time-series:
  #PROBLEM: Oh, oh: might result in negative values...
  abpmean_truth <- fit_individuals[[as.character(id)]]$plot_data$test
  abpmean_individual <- ts(simulate(model_individual, nsim = nsim, bootstrap = bootstrap, 
                        future = future, seed = seed))
  abpmean_pooled <- ts(simulate(model_pool, nsim = nsim, bootstrap = bootstrap, 
                        future = future, seed = seed))
  if(noise){
    abpmean_pooled <- abpmean_pooled + arima.sim(model=list(order = c(0, 0, 0)), n=nsim)
    abpmean_individual <- abpmean_individual + arima.sim(model=list(order = c(0, 0, 0)), n=nsim)
  }
  
  time <- seq(1, nsim, 1)
  
  #TO DO: Recode this...
  #Combine pooled and individual model into one  based on 
  #the number of interruptions
  start<-1
  abpmean_combined <- NULL
  diff<-nsim/(t+1)
  for(i in 1:(t+1)){
    if((i %% 2 != 0) & (start<nsim)){
      abpmean_combined <- c(abpmean_combined, abpmean_individual[start:(diff*i)])
      start <- start + diff
    }else if ((i %% 2 == 0) & (start<nsim)){
      abpmean_combined <- c(abpmean_combined, abpmean_pooled[start:(diff*i)])
      start <- start + diff
    }
  }
  if(length(abpmean_combined)<nsim){
    diff<-nsim-length(abpmean_combined)
    abpmean_combined<-c(abpmean_combined,abpmean_individual[(nsim-diff+1):nsim])
  }
  
  abpmean_combined <- ts(abpmean_combined)
  res <- data.frame(subject_id=id, time=time, W, abpmean=abpmean_combined)
  final <- new_Y_sol1(train_all = res, cutoff = 65)  
  return(list(dat=final,
              abpmean_combined=abpmean_combined,
              abpmean_individual=abpmean_individual,
              abpmean_pooled=abpmean_pooled,
              abpmean_truth=abpmean_truth))
  }
}
```

```{r, eval = FALSE, echo = FALSE, warning = FALSE}
### Simulate dataset used for the Combined SL
id<-20403
test_sample <- run_simulation(id=id, noise = TRUE, t = 2)

#Get all the rest of the samples:
new_sub_samples<-sub_samples[!sub_samples %in% id]
new_sub_df<-df[df$subject_id %in% new_sub_samples, c("subject_id","time", "gender","age","care_unit", "admission_type_descr","sapsi_first", "sofa_first", "amine","sedation","ventilation", "abpmean", "Y1")]
new_sub_df<-data.frame(new_sub_df)
new_sub_df<-rbind.data.frame(new_sub_df, test_sample$dat)
save(new_sub_df, file = here::here("Results/Nonstationary_ts", paste0("full_test_sample", id, ".Rdata")), compress = TRUE)
save(test_sample, file = here::here("Results/Nonstationary_ts", paste0("test_sample", id, ".Rdata")), compress = TRUE)
```

```{r, eval = TRUE, echo = FALSE, warning = FALSE}
load(here::here("Results/Nonstationary_ts","full_test_sample20403.Rdata"))
load(here::here("Results/Nonstationary_ts","test_sample20403.Rdata"))

#Plot the new time-series, and compare to the original 
#individual and pooled:
id<-20403

#Combine for one plot
ggplot() + geom_line(aes(x = as.numeric(time(test_sample$abpmean_combined)),
                         y = as.numeric(test_sample$abpmean_combined),
                         col = "blue")) +
           geom_line(aes(x = as.numeric(time(test_sample$abpmean_individual)),
                         y = as.numeric(test_sample$abpmean_individual),
                         col = "red")) +
           scale_color_discrete(name = "",
                                labels = c("Combined forecast", "Individual forecast")) +
           labs(title = paste0("Creation of an combined forecast for subject ", id),
                x = "Time in test set (minutes)",
                y = "Mean blood pressure") + theme(legend.position="top")

ggplot() + geom_line(aes(x = as.numeric(time(test_sample$abpmean_combined)),
                         y = as.numeric(test_sample$abpmean_combined),
                         col = "blue")) +
           geom_line(aes(x = as.numeric(time(test_sample$abpmean_pooled)),
                         y = as.numeric(test_sample$abpmean_pooled),
                         col = "red")) +
           scale_color_discrete(name = "",
                                labels = c("Combined forecast", "Pooled forecast")) +
           labs(title = paste0("Creation of an combined forecast for subject ", id),
                x = "Time in test set (minutes)",
                y = "Mean blood pressure") + theme(legend.position="top")
```

# Fit combined super learner

We fit the combined (global and individual) super learner across a range
of training data lengths. Ideally, we would like to see the Combined SL
switch between giving more weights to individual SL and pooled SL, depending
on where in the time-series we are and how much data we use for training.

\vspace{.2in}

We train the global super learner with baseline covariates, and with and without 
correlation-based screening of baseline covariates. We include the following 
baseline covariates:

* gender
* age
* care_unit
* admission_type_descr
* sapsi_first
* sofa_first

In addition, we include the following time-varying covariates:

* amine
* sedation
* ventilation 
* time

The combined online super learner also uses the individual super learner, which 
learns only from one sample at a time. For the individual super learner, we 
incorporate the following:

* baseline covariates mentioned above
* rolling origin cross-validation for the time series with
  * initial training set size 10 minutes
  * test set size 10 minutes
  * increase training set size by increments of 5 minutes

For the combined super learner, we incorporate a gap of 30 minutes between the 
last trained time point and the first prediction time point. 

For the base learning library, we consider 8 variations of xgboost. 

```{r, eval = FALSE, echo = FALSE, warning = FALSE}
load(here::here("Results/Nonstationary_ts", "full_test_sample20403.Rdata"))

source(here::here("R/CombinedOnlineSL.R"))
source(here::here("R/utils_mimic.R"))

train_all <- new_sub_df
#factor_to_indicators...
id=20403

######################################
#Specify the covariates and outcome:
######################################

outcome <- "Y1"
covars_baseline <- c("gender", "age","care_unit", "admission_type_descr", 
                      "sapsi_first", "sofa_first")
covars <- c("amine","sedation","ventilation","time")

#######################################
# Set the SL libraries:
#######################################

grid_params = list(max_depth=c(4,8),
                   eta = c(0.001, 0.01, 0.1, 0.2))
grid = expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
params_default = list(nthread = getOption("sl.cores.learners", 1))
xgb_learners = apply(grid, MARGIN = 1, function(params_tune) {
  do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))
  })

stack <- make_learner(
  Stack, xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]],
  xgb_learners[[4]], xgb_learners[[5]], xgb_learners[[6]], xgb_learners[[7]], xgb_learners[[8]]
)

### Learners with screeners:
screen_cor <- Lrnr_pkg_SuperLearner_screener$new("screen.corP")
cor_pipeline <- make_learner(Pipeline, screen_cor, stack)
stack_screen <- make_learner(Stack, cor_pipeline, stack)

###Regular Super-Learner option:
metalearner <- make_learner(Lrnr_nnls)
sl <- Lrnr_sl$new(learners = stack, metalearner = metalearner)

######################################
# Run the Combined Super Learner
######################################

#TO DO: Note that folds_rolling_window would actually be a much more suited CV for nonstationary ts.
times <-as.list(seq(30, 300, by = 30))

comSLsim_res <- lapply(times, function(x){
  #Ignore the fact we technically have an interrupted ts
  combine_SL(t = x, train_all = train_all, outcome=outcome, 
             stack_pool=stack, stack_individual=stack, stack_screen = stack_screen, sl=sl,
             covars=covars, covars_baseline = covars_baseline,
             gap=0, h=30, first_window=10, test_size=10, mini_batch=5,
             id=id)
})

save(comSLsim_res, file = here::here("Results/Nonstationary_ts", paste0("CombineSL_results", id, ".Rdata")), compress = TRUE)
```

```{r, echo=FALSE, eval=TRUE}
load(here::here("Results/Nonstationary_ts", "CombineSL_results20403.Rdata"))
times <-as.list(seq(30, 300, by = 30))

#############################################
# Assess the performance at each time step
#############################################

#Grab algorithm with smallest loss:
comSLsim_loss <- lapply(seq(comSLsim_res), function(i){
  names(which.min(comSLsim_res[[i]]$loss[[1]]))
})
comSLsim_loss <- cbind.data.frame(time=unlist(times), learner=unlist(comSLsim_loss))

comSLsim_loss %>%
  kable(format = "latex", booktabs = T, digits = 4, longtable = T,
        caption = "Picked learner at varying training size") %>%
  kable_styling(latex_options = c("striped", "repeat_header"), font_size = 7,
                position = "center")
```

