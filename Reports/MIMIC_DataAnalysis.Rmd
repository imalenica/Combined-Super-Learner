---
title: "MIMIC II Data Analysis"
author: "Ivana Malenica and Rachael Phillips"
date: "September, 2019"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{graphicx}
- \usepackage{lscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{float}
- \usepackage{booktabs}
- \usepackage{caption}
- \usepackage{capt-of}
---

```{r setup, echo = FALSE}
options(warn=-1)
suppressMessages(library(xtable))
suppressMessages(library(here))
suppressMessages(library(tidyverse))
suppressMessages(library(data.table))
suppressMessages(library(sl3))
suppressMessages(library(origami))
suppressMessages(library(SuperLearner))
suppressMessages(library(dplyr))
suppressMessages(library(kableExtra))
suppressMessages(library(pROC))
suppressMessages(library(knitr))
options(xtable.comment = FALSE)
source(here::here("R", "utils_mimic.R"))
source(here::here("R", "CombinedOnlineSL.R"))
load(here::here("Data", "mimic_all.Rdata"))

st_options(plain.ascii = FALSE,
           style       = "rmarkdown",
           footnote    = NA)
```

# Overview {-}

# Overview of the Data

We only considered patients that had:

* at least 8 hours of data.

* at most 1 min time gap between two consecutive measurements. 

In the table below, we explore how many patients had at least one hypotensive 
episode. The outcome function `Y1` was used to specify hypotensive events. By 
definition, a hypotensive episode for time $t$ is defined as either:

1. `abpmean` at time $t$ < 65 mmHg and the 5-minute window around time $t$ 
    (i.e., 10 time-points, $t_{-5}, ..., t_{+5}$) contains at least 5 
    time-points in which `abpmean` < 65.
2. the 5-minute window around time $t$ contains at least 8 time-points in which 
   `abpmean` < 65.

\vspace{.2in}
```{r, examine_data, echo=FALSE}
# Filter data so there is no more than 1 minute gap between observations.
# Subset data to samples that have at least 8 hours of data.
dat <- eval_missingness(min = 1, dataset = mimic_all, total_hrs = 8)[["dat"]] 
# remove these two subjects with too many unlikely low systolic bp values
ids_many_negative_abpsys <- c("15464", "4451")
dat <- dat[!(dat$subject_id %in% ids_many_negative_abpsys),]
dat <- new_Y_sol1(dat, window = 5, cutoff = 65)
dat$hypo_event <- dat$Y1

#Number of subjects with at least one event:
df <- dat %>%
  dplyr::select(c("subject_id", "hypo_event")) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(sum_hypo_events = sum(hypo_event)) %>%
  dplyr::select(c("subject_id", "sum_hypo_events")) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::summarize_all(unique)

#Samples with events:
sample_y1<-df[df$sum_hypo_events>0,1]
#Samples with no events:
sample_y0<-df[df$sum_hypo_events==0,1]

event_summary <- rbind.data.frame(dim(sample_y1)[1],
                                  dim(sample_y0)[1])
colnames(event_summary) <- "Number of Samples"
row.names(event_summary) <- c("> 0 hypotensive episodes",
                              "0 hypotensive episodes")
xtable(event_summary)
```

# Prepare Data for the Analysis

```{r, prep_data, results='asis', echo=FALSE}
#Add the time column
dat <- dat %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(time = seq(1,n(), 1))
# note that we could also use: dat$time <- dat$min_elapsed

outcome <- "hypo_event"

covars_baseline <- c("gender","age","care_unit", "admission_type_descr", 
                     "sapsi_first", "sofa_first", "bmi", "rank_icu",
                     "imputed_age", "imputed_bmi", "imputed_sofa", 
                     "imputed_sapsi")

covars_timevarying <- c("amine", "sedation", "ventilation", "spo2", "hr", 
                        "abpmean", "imputed_abpmean")
```

Below we list covariates we use for the further analysis. In particular, we can 
classify them as follows:

1. Baseline Covariates

```{r, baseline, echo=FALSE, eval=TRUE}
covars_baseline
```

1.Time-varying Covariates

```{r, timevar, echo=FALSE, eval=TRUE}
covars_timevarying
```

# Build the Combined Super Learner

The combined online super learner also uses the individual super learner, which 
learns only from one sample at a time. For the individual super learner, we 
incorporate the above described covariates as well. In addition, we consider two 
different Cross-Validation schemes that are used to *train* the combined super 
learner:

* Rolling Origin:
  * initial training set size 15 minutes
  * test set size 15 minutes
  * increase training set size by increments of 5 minutes
  * for example, the first fold trains on minutes 1-15 and tests on minutes 
  15-30, the second fold trains on minutes 1-20 and tests on minutes 
  20-35, and the third fold trains on minutes 1-25 and tests on minutes 
  25-40.
  
* Rolling Window:  
  * each window size is 15 minutes
  * test set size 15 minutes 
  * increase training set size by increments of 5 minutes
  * for example, the first fold trains on minutes 1-15 and tests on minutes 
  15-30, the second fold trains on minutes 5-20 and tests on minutes 
  20-35, and the third fold trains on minutes 10-25 and tests on minutes 
  25-40.
  
Note that the test sets described in the two cross-validation schemes are used 
to train the pooled/global and individual SLs. These test sets are not used to 
construct the weights for the combined SL.
  
To *construct* the combined super learner (i.e., combine the weights from the
pooled SL and individual SL), we incorporate a gap of 30 minutes between the 
last trained time point and the first prediction time point. Also, the
prediction period is the first 15-minutes following the 30-minute gap between
the training data. 

As explored in previous simulations, we only consider the binary outcome, 
instead of the continuous (even though the combined SL has support for both).
  
For the base learning library, we consider variations of xgboost: 

```{r, prep_SL, results='asis', echo=FALSE, eval=TRUE}
grid_params = list(max_depth = c(2,4,6,8),
                   eta = c(0.001, 0.01, 0.1, 0.2, 0.3))
grid = expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
params_default = list(nthread = getOption("sl.cores.learners", 1))
xgb_learners = apply(grid, MARGIN = 1, function(params_tune) {
  do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))
})
stack <- make_learner(Stack, xgb_learners)

screen_cor <- Lrnr_pkg_SuperLearner_screener$new("screen.corP")
cor_pipeline <- make_learner(Pipeline, screen_cor, stack)
stack_screen <- make_learner(Stack, cor_pipeline, stack)

metalearner <- make_learner(Lrnr_nnls)
sl <- Lrnr_sl$new(learners = stack, metalearner = metalearner)

stack
```

```{r, run_SL, results='asis', echo=FALSE, eval=FALSE}
times <- seq(30, 420, 30)
gaps <- seq(15,45,5)

ptm <- proc.time()
comSL_cvrw <- lapply(gaps, function(x){
  SL_times <- mclapply(times, function(y){
    combine_SL(train_all = dat, outcome, t = y, stack_pool = stack, 
               stack_individual = stack, stack_screen = stack_screen, sl = sl,
               covars = covars_timevarying, covars_baseline = covars_baseline,
               cv="folds_rolling_window", gap = x, h = 15, test_size = 15, 
               mini_batch = 5, window_size = 15)
    }, mc.cores = 20)
  names(SL_times) <- paste0(times)
  return(SL_times)
  })
names(comSL_cvrw) <- paste0(gaps)
proc.time() - ptm
save(comSL_cvrw, file = here("Results", "comSL_cvrw.Rdata"), compress = TRUE)
#       user     system    elapsed
# 230306.839   3460.473  24239.548
# 24239.548/60/60/7 ~ 1 hrs to run combine_SL across the times sequence
# 24239.548/60/60 = 6.7 hrs to run combine_SL across the times & gaps sequences

ptm <- proc.time()
comSL_cvro <- lapply(gaps, function(x){
  SL_times <- mclapply(times, function(y){
    combine_SL(train_all = dat, outcome, t = y, stack_pool = stack, 
               stack_individual = stack, stack_screen = stack_screen, sl = sl,
               covars = covars_timevarying, covars_baseline = covars_baseline,
               cv = "folds_rolling_origin", gap = x, h = 15, test_size = 15, 
               mini_batch = 5, window_size = 15)
    }, mc.cores = 20)
  names(SL_times) <- paste0(times)
  return(SL_times)
  })
names(comSL_cvro) <- paste0(gaps)
proc.time() - ptm
save(comSL_cvro, file = here("Results", "comSL_cvro.Rdata"), compress = TRUE)
#       user     system    elapsed
# 227174.380   4152.363  24080.005

# modify gap_training
ptm <- proc.time()
comSL_cvrw_gap_training <- lapply(gaps, function(x){
  SL_times <- mclapply(times[3:14], function(y){
    combine_SL(train_all = dat, outcome, t = y, stack_pool = stack, 
               stack_individual = stack, stack_screen = stack_screen, sl = sl,
               covars = covars_timevarying, covars_baseline = covars_baseline,
               cv="folds_rolling_window", gap = x, h = 15, test_size = 15, 
               mini_batch = 5, window_size = 15, gap_training = x)
    }, mc.cores = 20)
  names(SL_times) <- paste0(times[3:14])
  return(SL_times)
  })
names(comSL_cvrw_gap_training) <- paste0(gaps)
proc.time() - ptm
save(comSL_cvrw_gap_training, 
     file = here("Results", "comSL_cvrw_gap_training.Rdata"), compress = TRUE)

ptm <- proc.time()
comSL_cvro_gap_training <- lapply(gaps, function(x){
  SL_times <- mclapply(times[3:14], function(y){
    combine_SL(train_all = dat, outcome, t = y, stack_pool = stack, 
               stack_individual = stack, stack_screen = stack_screen, sl = sl,
               covars = covars_timevarying, covars_baseline = covars_baseline,
               cv="folds_rolling_origin", gap = x, h = 15, test_size = 15, 
               mini_batch = 5, window_size = 15, gap_training = x)
    }, mc.cores = 20)
  names(SL_times) <- paste0(times[3:14])
  return(SL_times)
  })
names(comSL_cvro_gap_training) <- paste0(gaps)
proc.time() - ptm
save(comSL_cvro_gap_training, 
     file = here("Results", "comSL_cvro_gap_training.Rdata"), compress = TRUE)


# when I added n_rounds = c(20,50) to grid_params total time was:
#  user     system    elapsed
# 320156.235   3894.858  44141.779
# 44141.779/60/60/7 = 1.75 hrs to run combine_SL across the times sequence
# 44141.779/60/60 ~ 12 hrs to run combine_SL across the times & gaps sequences
#save(comSL_cvrw, file = here::here("Results", "comSL_cvrw_12hr.Rdata"), 
#     compress = TRUE)
# nonzero <- lapply(comSL_cvrw, function(x){
#   lapply(x, function(y){
#     dat <- y$fit_coef
#     dplyr::filter(data.frame(dat), coefs > 0)
#   })})
# tbl <- lapply(nonzero, function(x){
#   bind_rows(x)
# })
# all <- bind_rows(tbl)
# levs_by_id <- all %>%
#   dplyr::select(c("learners")) %>%
#   dplyr::group_by(learners) %>%
#   tally()
# arrange(levs_by_id, desc(n))
# sum_by_id <- all %>%
#   dplyr::group_by(learners) %>%
#   dplyr::summarize(sum(coefs)) 
```

# Examine Results for Combined Super Learner

```{r, res_SL, results='asis', echo=FALSE, eval=TRUE}

load(here("Results", "comSL_cvrw.Rdata"))
load(here("Results", "comSL_cvro.Rdata"))

get_calculations <- function(list_gaps_times){
  calcs_gaps <- lapply(list_gaps_times, function(x){
    calcs_times <- lapply(x, function(y){
      calculations(y)
    })
    names(calcs_times) <- names(x)
    
    avg_loss_all <- t(cbind.data.frame(lapply(calcs_times, '[[', avg_loss)))
    
    avg_weight_all_max <- t(cbind.data.frame(lapply(calcs_times, function(z){
      z$max_SL_type[2]
    })))
    row.names(avg_weight_all_max) <- names(calcs_times)
    colnames(avg_weight_all_max) <- t(calcs_times[[1]]$max_SL_type[1])
    avg_weight_all_max <- cbind.data.frame(Time = row.names(avg_weight_all_max),
                                           avg_weight_all_max)
    avg_weight_all_max <- melt(avg_weight_all_max, id = "Time")
    avg_weight_all_max$Time <-
      as.numeric(levels(avg_weight_all_max$Time))[avg_weight_all_max$Time]
    
    avg_weight_all_ave <- t(cbind.data.frame(lapply(calcs_times, function(z){
      z$ave_SL_type[2]
    })))
    row.names(avg_weight_all_ave) <- names(calcs_times)
    colnames(avg_weight_all_ave) <- t(calcs_times[[1]]$ave_SL_type[1])
    avg_weight_all_ave <- cbind.data.frame(Time = row.names(avg_weight_all_ave),
                                           avg_weight_all_ave)
    avg_weight_all_ave <- melt(avg_weight_all_ave, id = "Time")
    avg_weight_all_ave$Time <-
      as.numeric(levels(avg_weight_all_ave$Time))[avg_weight_all_ave$Time]
    
    truths <- lapply(calcs_times, function(z){
      z$truth$truth
    })
    
    preds <- lapply(calcs_times, function(z){
      z$pred_fin$pred
    })
    
    all_results <- list(calcs_times = calcs_times, 
                        avg_loss_all = avg_loss_all, 
                        avg_weight_all_max = avg_weight_all_max,
                        avg_weight_all_ave = avg_weight_all_ave,
                        truths = truths,
                        preds = preds)
    return(all_results)
    })
  names(calcs_gaps) <- names(list_gaps_times)
  return(calcs_gaps)
}

calcs_cvro <- get_calculations(comSL_cvro)

# ggplot(weight_all_max, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over time for Rolling Window CV") + labs(x="time point (minutes)", y="Super Learner Coefficient", sep=" ")

ggplot(weight_all_ave, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over varying Training Time for Rolling Window CV") + labs(x="Training time (minutes)", y="Super Learner Coefficient", sep=" ") + theme_bw()

print(xtable(data.frame(loss_all_t), caption='\\textbf{Risk for all different SLs considered for Rolling Window CV}', digits=10), include.rownames=TRUE,caption.placement = "top", size="\\fontsize{9pt}{10pt}\\selectfont")
```

```{r, roc_SL, results='asis', echo=FALSE, eval = FALSE}
roc(calc_t60$truth$truth, calc_t60$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=60")

roc(calc_t120$truth$truth, calc_t120$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=120")

roc(calc_t180$truth$truth, calc_t180$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=180")

roc(calc_t240$truth$truth, calc_t240$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=240")

roc(calc_t300$truth$truth, calc_t300$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=300")

roc(calc_t360$truth$truth, calc_t360$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=360")
```



```{r, res_SL_origin, results='asis', echo=FALSE, eval=TRUE}
load(here("Results", "comSL_cvro.Rdata"))
calc_t60<-calculations(comSL_cvro[[1]])
calc_t120<-calculations(comSL_cvro[[2]])
calc_t180<-calculations(comSL_cvro[[3]])
calc_t240<-calculations(comSL_cvro[[4]])
calc_t300<-calculations(comSL_cvro[[5]])
calc_t360<-calculations(comSL_cvro[[6]])
calc_t420<-calculations(comSL_cvro[[7]])

loss_all_t<-t(cbind.data.frame(calc_t60$loss,calc_t120$loss,calc_t180$loss,
                               calc_t240$loss,calc_t300$loss, calc_t360$loss,
                               calc_t420$loss))
row.names(loss_all_t)<-c("t=60","t=120","t=180","t=240","t=300","t=360","t=420")

weight_all_max<-t(cbind.data.frame(calc_t60$max_SL_type[2],calc_t120$max_SL_type[2],
                                   calc_t180$max_SL_type[2],calc_t240$max_SL_type[2],
                                   calc_t300$max_SL_type[2],calc_t360$max_SL_type[2],
                                   calc_t420$max_SL_type[2]))
row.names(weight_all_max)<-c("60","120","180","240","300","360","420")
colnames(weight_all_max)<-t(calc_t60$max_SL_type[1])
weight_all_max<-cbind.data.frame(Time=row.names(weight_all_max),weight_all_max)
weight_all_max<-melt(weight_all_max, id="Time")
weight_all_max$Time<-as.numeric(levels(weight_all_max$Time))[weight_all_max$Time]

# ggplot(weight_all_max, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over time for Rolling Origin CV") + labs(x="time point (minutes)", y="Super Learner Coefficient", sep=" ")

weight_all_ave<-t(cbind.data.frame(calc_t60$ave_SL_type[2],calc_t120$ave_SL_type[2],
                                   calc_t180$ave_SL_type[2],calc_t240$ave_SL_type[2],
                                   calc_t300$ave_SL_type[2],calc_t360$ave_SL_type[2],
                                   calc_t420$ave_SL_type[2]))
row.names(weight_all_ave)<-c("60","120","180","240","300","360","420")
colnames(weight_all_ave)<-t(calc_t60$ave_SL_type[1])
weight_all_ave<-cbind.data.frame(Time=row.names(weight_all_ave),weight_all_ave)
weight_all_ave<-melt(weight_all_ave, id="Time")
weight_all_ave$Time<-as.numeric(levels(weight_all_ave$Time))[weight_all_ave$Time]

ggplot(weight_all_ave, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over varying Training Time for Rolling Origin CV") + labs(x="Training time (minutes)", y="Super Learner Coefficient", sep=" ") + theme_bw()

print(xtable(data.frame(loss_all_t), caption='\\textbf{Risk for all different SLs considered for Rolling Origin CV}', digits=10), include.rownames=TRUE,caption.placement = "top", size="\\fontsize{9pt}{10pt}\\selectfont")
```


```{r, roc_SL_origin, results='asis', echo=FALSE, eval=TRUE, eval = FALSE}
roc(calc_t60$truth$truth, calc_t60$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=60")

roc(calc_t120$truth$truth, calc_t120$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=120")

roc(calc_t180$truth$truth, calc_t180$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=180")

roc(calc_t240$truth$truth, calc_t240$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=240")

roc(calc_t300$truth$truth, calc_t300$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=300")

roc(calc_t360$truth$truth, calc_t360$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=360")
```