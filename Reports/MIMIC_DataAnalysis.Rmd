---
title: "MIMIC II Data Analysis"
author: "Ivana Malenica and Rachael Phillips"
date: "September, 2019"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
header-includes:
- \usepackage{graphicx}
- \usepackage{lscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{float}
---

```{r setup, echo = FALSE}
options(warn=-1)
suppressMessages(library(xtable))
suppressMessages(library(here))
suppressMessages(library(tidyverse))
suppressMessages(library(data.table))
suppressMessages(library(sl3))
suppressMessages(library(origami))
suppressMessages(library(SuperLearner))
suppressMessages(library(dplyr))
suppressMessages(library(kableExtra))
suppressMessages(library(summarytools))
suppressMessages(library(pROC))
options(xtable.comment = FALSE)
source(here::here("R", "utils_mimic.R"))
source(here::here("R", "CombinedOnlineSL.R"))
load(here::here("Data", "mimic_all.Rdata"))

st_options(plain.ascii = FALSE,
           style       = "rmarkdown",
           footnote    = NA)
```

# Overview {-}

# Overview of the Data

We only considered patients that had:

* at least 8 hours of data.

* at most 1 min time gap between two consecutive measurements. 

\vspace{.2in}

We can see a list of all the covariates available, as well as the basic 
summary statistic for each below. 

\vspace{.2in}
```{r, examine_data, results='asis', echo=FALSE}
#Filter data so there is no more that 3 minute gap between observations.
#Subset data to samples that have at least 8 hours of data.
dat <- eval_missingness(min = 1, dataset = mimic_all, total_hrs = 8)[["dat"]] 
dat_summary <- dat[,c("abpsys","abpdias","abpmean","spo2", 
                      "imputed_abpmean","imputed_abpsys_abpdias","hypo_event","amine",
                      "sedation","ventilation","rank_icu","gender",
                      "age","sapsi_first","sofa_first","bmi",
                      "care_unit","admission_type_descr","imputed_age","imputed_bmi",
                      "imputed_sofa","imputed_sapsi")]

names(dat_summary)

#Summary of data:
print(dfSummary(dat_summary), method = "render", display.labels=FALSE, headings=TRUE,
      graph.col=TRUE, graph.magnif=0.8, silent=TRUE,
      report.title="Summary of all the covariates")
```

\vspace{.2in}

We further explore the number of total hypotensive episodes experiences per each 
patient.

\vspace{.2in}

```{r, examine_data_2, results='asis', echo=FALSE}
dat$hypo_event <- as.numeric(levels(dat$hypo_event))[dat$hypo_event]

#Number of subjects with at least one event:
df <- dat %>%
  dplyr::select(c("subject_id", "hypo_event")) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(sum_all_events = sum(hypo_event)) %>%
  dplyr::select(c("subject_id", "sum_all_events")) %>%
  dplyr::group_by(subject_id) %>%
  dplyr::summarize_all(unique)

#Summary of data:
print(dfSummary(df[,2]), method = "render", display.labels=FALSE, headings=TRUE,
      graph.col=TRUE, graph.magnif=0.8, silent=TRUE,
      report.title="Summary of the sum of hypotensive events by patient")
```

Finally, we expore how many patients had at least one episode. 
442 of the 698 subjects experienced at least one hypotensive event, and the 
outcome function `Y1` was used to specify hypotensive events. By definition, 
an hypotensive episode is defined as a 5 minute window with mean arterial pressure (MAP) 
below 62 mmHg.

```{r, examine_data_3, results='asis', echo=FALSE}
#Samples with events:
sample_y1<-df[df$sum_all_events>0,1]
#Samples with no events:
sample_y0<-df[df$sum_all_events==0,1]

event_summary <- rbind.data.frame(dim(sample_y1)[1],
                                  dim(sample_y0)[1])
colnames(event_summary) <- "Number of Events"
row.names(event_summary) <- c("Samples with > 0 episodes",
                              "Samples with 0 episodes")

print(dfSummary(event_summary), method = "render", display.labels=FALSE, headings=TRUE,
      graph.col=TRUE, graph.magnif=0.8, silent=TRUE,
      report.title="Summary of the sum of hypotensive events by patient")
```

# Prepare Data for the Analysis

```{r, prep_data, results='asis', echo=FALSE}
#Add the time column
dat <- dat %>%
  dplyr::group_by(subject_id) %>%
  dplyr::mutate(time = seq(1,n(), 1))

outcome <- "hypo_event"

covars_baseline <- c("gender","age","care_unit", "admission_type_descr", 
                     "sapsi_first", "sofa_first", "bmi", "rank_icu",
                     "imputed_age", "imputed_bmi", "imputed_sofa", 
                     "imputed_sapsi")

covars_timevarying <- c("amine", "sedation", "ventilation", "spo2", "hr", 
                        "abpmean", "imputed_abpmean")
```

Below we list covariates we use for the further analysis. In particular, we can 
classify them as follows:

1. Baseline Covariates

```{r, baseline, echo=FALSE, eval=TRUE}
covars_baseline
```

1.Time-varying Covariates

```{r, timevar, echo=FALSE, eval=TRUE}
covars_timevarying
```

# Build the Combined Super Learner

The combined online super learner also uses the individual super learner, which 
learns only from one sample at a time. For the individual super learner, we 
incorporate the above described covariates as well. In addition, we consider two 
different Cross-Validation schemes:

* Rolling Origin:
  * initial training set size 15 minutes
  * test set size 15 minutes
  * increase training set size by increments of 5 minutes

* Rolling Window:  
  * each window size is 15 minutes
  * test set size 15 minutes
  * increase training set size by increments of 5 minutes
  
For the combined super learner, we  incorporate a gap of 30 minutes between the 
last trained time point and the first prediction time point. If round hour, we include
a gap of 0, due to the data-setup. Therefore, the
prediction is for a 15 minute period 30 minutes in the future (since the last 
trained time-point). 

As explored in previous simulations, we only consider the binary outcome, 
instead of the continuous (even though the combined Super Learner has support for both).
  
For the base learning library, we consider 8 variations of xgboost: 

```{r, prep_SL, results='asis', echo=FALSE, eval=TRUE}
grid_params = list(max_depth=c(4,8),
                   eta = c(0.001, 0.01, 0.1, 0.2))
grid = expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
params_default = list(nthread = getOption("sl.cores.learners", 1))
xgb_learners = apply(grid, MARGIN = 1, function(params_tune) {
  do.call(Lrnr_xgboost$new, c(params_default, as.list(params_tune)))
})

stack <- make_learner(
  Stack, xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]],
  xgb_learners[[4]], xgb_learners[[5]], xgb_learners[[6]], xgb_learners[[7]], 
  xgb_learners[[8]])

screen_cor <- Lrnr_pkg_SuperLearner_screener$new("screen.corP")
cor_pipeline <- make_learner(Pipeline, screen_cor, stack)
stack_screen <- make_learner(Stack, cor_pipeline, stack)

metalearner <- make_learner(Lrnr_nnls)
sl <- Lrnr_sl$new(learners = stack, metalearner = metalearner)

stack
```

```{r, run_SL, results='asis', echo=FALSE, eval=FALSE}
times <- seq(30, 420, by = 30)[-1]

comSL_cvrw <- lapply(times, function(x){
  combine_SL(train_all = dat, outcome, t = x, stack_pool = stack, 
             stack_individual = stack, stack_screen = stack_screen, sl = sl,
             covars = covars_timevarying, covars_baseline = covars_baseline,
             cv = "folds_rolling_window", gap = 30, h = 15, 
             test_size = 15, mini_batch = 5, window_size = 15)
  })
names(comSL_cvrw) <- paste0(times, " min training time")
save(comSL_cvrw, file = here::here("Results", "comSL_cvrw.Rdata"), 
     compress = TRUE)

comSL_cvro <- lapply(times, function(x){
  combine_SL(train_all = dat, outcome, t = x, stack_pool = stack, 
             stack_individual = stack, stack_screen = stack_screen, sl = sl,
             covars = covars_timevarying, covars_baseline = covars_baseline,
             cv = "folds_rolling_origin", gap = 30, h = 15, 
             test_size = 15, mini_batch = 5, window_size = 15)
})
names(comSL_cvro) <- paste0(times, " min training time")
save(comSL_cvro, file = here::here("Results", "comSL_cvro.Rdata"), 
     compress = TRUE)
```

# Examine Results for Combined Super Learner

```{r, res_SL, results='asis', echo=FALSE, eval=TRUE}
calculations = function(res){
  
  #Get all predictions in a data-frame:
  preds_fin<-as.data.frame(res$preds_fin)
  preds_regSL<-as.data.frame(res$pred_regular_SL)
  truth<-as.data.frame(res$truth)
  names(preds_regSL)<-names(preds_fin)
  names(truth)<-names(preds_fin)
  
  #preds_indSL<-as.data.frame(res$pred_regular_individual_SL)
  #names(preds_indSL)<-names(preds_fin)
  
  #Get all predictions in a data-frame:
  preds_fin<-as.data.frame(res$preds_fin)
  preds_regSL<-as.data.frame(res$pred_regular_SL)
  truth<-as.data.frame(res$truth)
  names(preds_regSL)<-names(preds_fin)
  names(truth)<-names(preds_fin)
  
  #preds_indSL<-as.data.frame(res$pred_regular_individual_SL)
  #names(preds_indSL)<-names(preds_fin)
  
  #AUC over ALL validation time-points
  pred_fin<-data.frame(pred=unlist(preds_fin))
  pred_regSL<-data.frame(pred=unlist(preds_regSL))
  truth<-data.frame(truth=unlist(truth))
  #pred_indSL<-data.frame(pred=unlist(preds_indSL))
  
  #(averaged over time and all samples):
  loss<-colMeans(res$losses_all)
  names(loss)<-names(res$losses_all)
  
  #Look at the weights as an average over all samples:
  fit_coef <- lapply(res$fit_coef, function(x){
    rownames(x) <- x$learners
    return(x[,2:3])
    })
  weights<- data.frame(bind_cols(fit_coef))
  toDelete <- seq(1, dim(weights)[2], 2)
  weights <-  weights[,-toDelete]
  weight<-data.frame(rowMeans(weights, na.rm = TRUE))
  names(weight)<-"Coefficient"
  row.names(weight)<-res$fit_coef[[1]]$learners
  weight<-weight/sum(weight)
  #weight_lrn<-cbind.data.frame(Learner=res$fit_coef[[1]]$learners,Coefficients=weight)
  #weight<-weight_lrn[order(weight, decreasing = TRUE),1:2]  

  #Make a more general category:
  #1. picks the best algorithm from each category? 
  #2. averages over the algorithms?
  
  weight$SL_type<-NA
  weight[grepl("GlobalSL_screenbaseline", row.names(weight), fixed = TRUE),"SL_type"]<-"GlobalSL_Screen_Baseline"
  weight[grepl("GlobalSL_baseline", row.names(weight), fixed = TRUE),"SL_type"]<-"GlobalSL_Baseline"
  weight[grepl("GlobalSL_screen_", row.names(weight), fixed = TRUE),"SL_type"]<-"GlobalSL_Screen"
  weight[grepl("IndividualSL_", row.names(weight), fixed = TRUE),"SL_type"]<-"IndividualSL"
  weight[is.na(weight$SL_type),"SL_type"]<-"GlobalSL"
  
  #1. Best algorithm from each category
  max_SL_type <- weight %>% group_by(SL_type) %>% summarise(max=max(Coefficient))
  #2. Average of algorithms for each category
  ave_SL_type <- weight %>% group_by(SL_type) %>% summarise(ave=mean(Coefficient))

  return(list(pred_fin=pred_fin,
              pred_regSL=pred_regSL,
              truth=truth,
              loss=loss,
              weight=weight,
              max_SL_type=max_SL_type,
              ave_SL_type=ave_SL_type))
}
load(here("Results", "comSL_cvrw.Rdata"))
calc_t60<-calculations(comSL_cvrw1[[1]])
calc_t120<-calculations(comSL_cvrw1[[2]])
calc_t180<-calculations(comSL_cvrw1[[3]])
calc_t240<-calculations(comSL_cvrw1[[4]])
calc_t300<-calculations(comSL_cvrw1[[5]])
calc_t360<-calculations(comSL_cvrw1[[6]])
calc_t420<-calculations(comSL_cvrw1[[7]])

loss_all_t<-t(cbind.data.frame(calc_t60$loss,calc_t120$loss,calc_t180$loss,
                               calc_t240$loss,calc_t300$loss, calc_t360$loss,
                               calc_t420$loss))
row.names(loss_all_t)<-c("t=60","t=120","t=180","t=240","t=300","t=360","t=420")

weight_all_max<-t(cbind.data.frame(calc_t60$max_SL_type[2],calc_t120$max_SL_type[2],
                                   calc_t180$max_SL_type[2],calc_t240$max_SL_type[2],
                                   calc_t300$max_SL_type[2],calc_t360$max_SL_type[2],
                                   calc_t420$max_SL_type[2]))
row.names(weight_all_max)<-c("60","120","180","240","300","360","420")
colnames(weight_all_max)<-t(calc_t60$max_SL_type[1])
weight_all_max<-cbind.data.frame(Time=row.names(weight_all_max),weight_all_max)
weight_all_max<-melt(weight_all_max, id="Time")
weight_all_max$Time<-as.numeric(levels(weight_all_max$Time))[weight_all_max$Time]

ggplot(weight_all_max, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over time") + labs(x="time point (minutes)", y="Super Learner Coefficient", sep=" ")

weight_all_ave<-t(cbind.data.frame(calc_t60$ave_SL_type[2],calc_t120$ave_SL_type[2],
                                   calc_t180$ave_SL_type[2],calc_t240$ave_SL_type[2],
                                   calc_t300$ave_SL_type[2],calc_t360$ave_SL_type[2],
                                   calc_t420$ave_SL_type[2]))
row.names(weight_all_ave)<-c("60","120","180","240","300","360","420")
colnames(weight_all_ave)<-t(calc_t60$ave_SL_type[1])
weight_all_ave<-cbind.data.frame(Time=row.names(weight_all_ave),weight_all_ave)
weight_all_ave<-melt(weight_all_ave, id="Time")
weight_all_ave$Time<-as.numeric(levels(weight_all_ave$Time))[weight_all_ave$Time]

ggplot(weight_all_ave, aes(x=Time,y=value,colour=variable)) + geom_line(aes(group=variable),size=0.4) + geom_point(shape=1) + ggtitle("Super Learner Weights over varying Training Time") + labs(x="Training time (minutes)", y="Super Learner Coefficient", sep=" ") + theme_bw()

print(xtable(data.frame(loss_all_t), caption='\\textbf{Risk for all different SLs considered}', digits=10), include.rownames=TRUE,caption.placement = "top", size="\\fontsize{9pt}{10pt}\\selectfont")
```
## AUC across various training times

```{r, roc_SL, results='asis', echo=FALSE, eval=TRUE}
roc(calc_t60$truth$truth, calc_t60$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=60")

roc(calc_t120$truth$truth, calc_t120$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=120")

roc(calc_t180$truth$truth, calc_t180$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=180")

roc(calc_t240$truth$truth, calc_t240$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=240")

roc(calc_t300$truth$truth, calc_t300$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=300")

roc(calc_t360$truth$truth, calc_t360$pred_fin$pred, plot=TRUE, col="#377eb8", lwd=4, print.auc=TRUE, main="Combined Online Super Learner for t=360")
```